{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, DataLoader\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "\n",
    "class MaxIndDataset(InMemoryDataset):\n",
    "    def __init__(self, root):\n",
    "        self.label_frame = pd.read_csv(osp.join(root, \"label.csv\"))\n",
    "        self.weight_frame = pd.read_csv(osp.join(root, \"weight.csv\"))\n",
    "        self.root_dir = root\n",
    "        self.num_graphs = len(self.label_frame)\n",
    "        super(MaxIndDataset, self).__init__(root)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "   \n",
    "    @property   \n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    def _download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for i in range(self.num_graphs):\n",
    "            graph_name = os.path.join(self.root_dir, self.label_frame.iloc[i, 0])\n",
    "            graph = nx.read_adjlist(graph_name, nodetype=int)\n",
    "   \n",
    "            weight = torch.tensor(self.weight_frame.iloc[i, 1:], dtype=torch.float)\n",
    "            label = torch.tensor(self.label_frame.iloc[i, 1:], dtype=torch.long)\n",
    "        \n",
    "            data = from_networkx(graph)\n",
    "            data.x = weight\n",
    "            data.y = label\n",
    "            \n",
    "            data_list.append(data)\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "def draw_entry(entry):\n",
    "    g = to_networkx(entry)\n",
    "    label = entry[\"y\"]\n",
    "    \n",
    "    # Create color map from selected nodes, green for selected, grey for unselected.\n",
    "    color_map = [\"grey\"] * len(g.nodes)\n",
    "\n",
    "    for i in np.flatnonzero(label):\n",
    "        color_map[i] = \"green\"\n",
    "        \n",
    "    node_labels = entry[\"x\"]\n",
    "    \n",
    "    if not torch.equal(node_labels, torch.ones(len(g.nodes))):\n",
    "        node_labels = {k: \"{0}:\\n{1:.3f}\".format(k, v) for (k, v) in enumerate(node_labels)}\n",
    "    else:\n",
    "        node_labels = {k: k for k in g.nodes}\n",
    "    \n",
    "    plt.figure()\n",
    "    pos = nx.circular_layout(g)\n",
    "    nx.draw(g, pos, node_size=2000, width = 1, node_color = color_map)\n",
    "    nx.draw_networkx_labels(g, pos, node_labels)\n",
    "    plt.show()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_loader(dataset, train_size, test_size, batch_size):\n",
    "    dataset.shuffle()\n",
    "    size = len(dataset)\n",
    "    \n",
    "    tr_i = int(size * train_size)\n",
    "    val_i = tr_i + int(size * test_size)\n",
    "    train_loader = DataLoader(dataset[:tr_i], batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset[tr_i: val_i])\n",
    "    test_loader = DataLoader(dataset[val_i:])\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "bin_80 = MaxIndDataset('data/binomial_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = split_loader(bin_80, .7, .2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[1600], edge_index=[2, 25120], x=[1600], y=[1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([2, 25120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for b in train_loader:\n",
    "    print(b)\n",
    "    print(b.x.size())\n",
    "    print(b.edge_index.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxIndDataset(5600)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class BasicNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicNet, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        weight = data[\"x\"].view(-1, 1)\n",
    "        edge_index = data[\"edge_index\"]\n",
    "        x = self.conv1(weight, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class MultiNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiNet, self).__init__()\n",
    "        self.conv_in = GCNConv(1, 32)\n",
    "        self.conv_mid = GCNConv(32, 32)\n",
    "        self.conv_out = GCNConv(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        weight = data[\"x\"].view(-1, 1)\n",
    "        edge_index = data[\"edge_index\"]\n",
    "        x = self.conv_in(weight, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_mid(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_mid(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_mid(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_mid(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_out(x, edge_index)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681e5a769c054a70b276abdbc2b3d69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zach/anaconda3/envs/deepkidney/lib/python3.7/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([1600])) that is different to the input size (torch.Size([1600, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 0.5119, Val Loss: 0.482\n",
      "Epoch: 001, Train Loss: 0.4689, Val Loss: 0.457\n",
      "Epoch: 002, Train Loss: 0.4450, Val Loss: 0.434\n",
      "Epoch: 003, Train Loss: 0.4349, Val Loss: 0.423\n",
      "Epoch: 004, Train Loss: 0.4319, Val Loss: 0.434\n",
      "Epoch: 005, Train Loss: 0.4408, Val Loss: 0.437\n",
      "Epoch: 006, Train Loss: 0.4567, Val Loss: 0.443\n",
      "Epoch: 007, Train Loss: 0.4401, Val Loss: 0.436\n",
      "Epoch: 008, Train Loss: 0.4377, Val Loss: 0.430\n",
      "Epoch: 009, Train Loss: 0.4376, Val Loss: 0.427\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "### Runs but losses dont go down, seems to converge to around 0.48\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MultiNet().to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-4)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, item in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        item = item.to(device)\n",
    "        outputs = model(item)\n",
    "        \n",
    "        loss = criterion(outputs, item[\"y\"].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    running_acc = 0.0 # Implement later\n",
    "    running_loss = 0.0\n",
    "    for i, item in enumerate(loader):\n",
    "        item = item.to(device)\n",
    "        outputs = model(item)\n",
    "        loss = criterion(outputs.view(-1, 1), item[\"y\"].float().view(-1, 1))\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "        \n",
    "for epoch in tqdm_notebook(range(10)):\n",
    "    train_loss = train(epoch)\n",
    "    val_loss = evaluate(val_loader)\n",
    "    print(('Epoch: {:03d}, Train Loss: {:.4f}, Val Loss: {:.3f}').format(epoch, train_loss, val_loss))\n",
    "\n",
    "print('Finished Training')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv_in.weight \t torch.Size([1, 32])\n",
      "conv_in.bias \t torch.Size([32])\n",
      "conv_mid.weight \t torch.Size([32, 32])\n",
      "conv_mid.bias \t torch.Size([32])\n",
      "conv_out.weight \t torch.Size([32, 1])\n",
      "conv_out.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/unweighted_multinet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepkidney",
   "language": "python",
   "name": "deepkidney"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
